(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{422:function(t,s,a){"use strict";a.r(s);var e=a(43),r=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"一致性哈希算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一致性哈希算法"}},[t._v("#")]),t._v(" 一致性哈希算法")]),t._v(" "),a("p",[t._v("传统的哈希算法可以用下面的式子描述：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("location = hash(key) mode size\n")])])]),a("p",[t._v("其实 size 一般是固定不变的。")]),t._v(" "),a("p",[t._v("显然根据这个式子，如果 size 发生了变化，那么所有的元素都需要重新进行哈希运算，这无疑需要很大的成本。")]),t._v(" "),a("p",[t._v("那么如果 size 的大小发生变化了呢？传统上来说，这个size指的是内存，不增不减，就在那里。如果我们换一个场景，\n假如把内存换成多台服务器，这个数量暂定为10，如果因为某种原因需要增加或减少服务器，也就是size就会发生变化，\n用户请求就不能访问到正确的服务器，也就需要重新计算，这样就不是很友善了。")]),t._v(" "),a("h2",{attrs:{id:"什么是一致性哈希"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#什么是一致性哈希"}},[t._v("#")]),t._v(" 什么是一致性哈希")]),t._v(" "),a("ul",[a("li",[t._v("环\n"),a("ul",[a("li",[t._v("用来表示请求和服务器节点")])])]),t._v(" "),a("li",[t._v("存储位置的数量不是固定的，首尾相连的环，可以认为点是无限的。")]),t._v(" "),a("li",[t._v("用户请求使用同样的哈希函数放置到环上")]),t._v(" "),a("li",[t._v("每个请求可以被顺时针遍历到的第一个节点服务，可以想象的是，每个节点拥有环上的一段区间")]),t._v(" "),a("li",[t._v("假如一个节点挂掉了，也只有该节点的区间受到区间。")])]),t._v(" "),a("h2",{attrs:{id:"实现方式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现方式"}},[t._v("#")]),t._v(" 实现方式")])])}),[],!1,null,null,null);s.default=r.exports}}]);